\section{Tightness of the Volume Lower Bound}
\label{sec:tightness}

In this section, we will show that the volume lower bound \eqref{eq:vol-lb} is
tight within a logarithmic factor. 

\tightvollb*
% \begin{theorem}\label{thm:tightness}
% There exists a universal constant $C \geq 1$ such that the following holds. Let
% $K \subseteq \R^n$ be a convex body $\R^n$, and let $u_1, \ldots, u_N \in \R^n$.
% Then, the following holds:
% \begin{enumerate}
% \item $1 \le \frac{\hd((u_i)_{i = 1}^N, K)}{\vollb^{\rm h}((u_i)_{i = 1}^N, K)} 
%          \le C(1+\log n)$.\\
% \item $\hd((u_i)_{i = 1}^N, K) \leq C \sum_{k=1}^n \frac{1}{k} \vollb^{\rm
% h}_k((u_i)_{i=1}^N,K)$.
% \end{enumerate}
% Furthermore, there exists a polynomial time algorithm which can compute a
% coloring of $(u_i)_{i=1}^N$ of $K$-discrepancy at most $C(1 + \log n)\vollb^{\rm
% h}((u_i)_{i=1}^N,K)$. \dnote{Fix the proof to show the above.} 
% \end{theorem}

The main technical result of this section is that the volume lower bound,
restricted to subsets of size at least $\Omega(n)$, is in fact an upper bound on
the discrepancy of so-called partial colorings. This allows us to easily recover
Theorem~\ref{thm:tightness} using $O(\log n)$ partial coloring phases in the
standard way. We state our technical result below, restricted to the case where
the vectors are aligned with the standard basis. We note that since the output
norm is general, this is essentially without loss of generality. For a vector $x
\in [-1,1]^n$, we use the notation $\bnds(x) = \set{i \in [n]: x_i \in
\set{-1,1}}$, to denote the coordinates in $x$ set to $\pm 1$. 

\begin{lemma}[Partial Colorings via Volume] \label{lem:partial-via-volume}
There exists a universal constants $C \geq 1, \eps_0 \in (0,1), \delta \in (0,1)$, such that
for any $y \in (-1,1)^n$ and symmetric convex body $K \subseteq \R^n$ satisfying
$\forall S \subseteq [n]$, $|S| = \ceil{\delta n}$, $\vol_{|S|}(K_S) \geq 1$, there
exists a polynomial time algorithm which with high probability finds $x \in
[-1,1]^n$ with $|\bnds(x)| \geq \ceil{\eps_0 n}$ and
$x-y \in C K$.  
\end{lemma}

We now give the straightforward reduction from Theorem~\ref{thm:tightness} to
Lemma~\ref{lem:partial-via-volume}.

\begin{proof}[Proof of Theorem~\ref{thm:tightness}]
By Lemma~\ref{lem:vol-lb}, we may restrict attention to the upper bound. In
particular, given $u_1,\dots,u_N \in \R^n$ and a convex body $K$ in $\R^n$, it
suffices to show that $\disc((u_i)_{i=1}^N) \leq C(1+\log n)\vollb^{\rm
h}((u_i)_{i=1}^N,K)$.  

To begin, we compute a basic solution to the linear program $\sum_{i=1}^N x_i
u_i = 0$, $x \in [-1,1]^N$. After relabeling, we may assume the variables not
hitting their $\set{-1,1}$ bounds are $x_1,\dots,x_l$, noting that if there are
no such variables we already have a $0$ discrepancy coloring. Since
$x$ is basic, we know that the vectors $u_1,\dots,u_l$ must be linearly
independent. Therefore, we may apply a invertible linear
transformation $T:\R^n \rightarrow \R^n$ sending $u_1,\dots,u_l$ to
$e_1,\dots,e_l$. In particular, letting $K' := TK$, we have that 
\begin{align*}
\disc((u_i)_{i=1}^N,K) &\leq \min_{z \in \set{-1,1}^l} \|\sum_{i=1}^l z_i e_i +
\sum_{i=l+1}^N x_i T u_i\|_{K'} \\
                &= \min_{z \in \set{-1,1}^l} \|\sum_{i=1}^l (z_i-x_i)e_i\|_{K'}, 
\end{align*}
Furthermore, a direct computation shows that
\[
\vollb^{\rm h}((u_i)_{i=1}^l,K) = \vollb^{\rm h}((e_i)_{i=1}^l,K') = \max_{S \subseteq [l]}
\vol_{|S|}(K'_S)^{-1/|S|} \text{ .}
\] 
Let us assume that we have computed $M > 0$ satisfying 
\[
M/2 \leq \vollb^{\rm h}((e_i)_{i=1}^l,K') \leq M. 
\]
From here, it suffices to compute $z \in
\set{-1,1}^l$ such that $\sum_{i=1}^l (z_i-x_i) e_i \in O(M\log n) K'$. Note
that by assumption on $M$, $\vol(MK'_S) \geq 1, \forall S \subseteq [l]$.
Therefore, repeatedly applying Lemma~\ref{lem:partial-via-volume} on $MK'$, letting $x^0 := x$ we compute a sequence
$x^1,\dots,x^T \in [-1,1]^l$, $T = \lceil \log l/\eps_0
\rceil = O(\log n)$, such that $\forall t \in [T]$, we have that

\begin{enumerate}
\item $\sum_{i=1}^l (x^t_i-x^{t-1}_i)e_i \in O(M) K'$.
\item $|\set{i \in [l]: x^t_i \in (-1,1)}| \leq (1-\eps_0)|\set{i \in [l]:
x^{t-1}_i \in (-1,1)}|$.
\end{enumerate}

By our choice of $T$, it is direct to check that $x^T \in \set{-1,1}^l$ and by
the triangle inequality that $\sum_{i=1}^l (x^T_i-x^0_i)e_i \in T M K' = O(M\log n) K'$. Thus, setting $z = x^T$ satisfies the requirements.

We now discuss the computation of $M$. We first note that 
\[
M_1 := \max_{i \in [l]} \vol_1(K'_i)^{-1} = \max_{i \in [l]} \|e_i\|_{K'} =
\max_{i \in [l]} \|u_i\|_K \text{ ,}
\]
and thus the restricted maximum can be efficiently computed. Note that by
construction \[{\rm conv}\{\pm e_1,\dots, \pm e_l\}/M_1 \subseteq K'_{[l]}.\] Thus,
for any $S \subseteq [l]$,$|S|=k$, we see that
\[
\vol_k(l M_1 K'_S) \geq \vol_{k}(l \cdot {\rm conv}(\pm e_i: i \in S)) = \frac{(2l)^k}{k!}
 \geq 1 \text{ .}
\]
In particular, we get that $M_1 \leq \vollb^{\rm h}((e_i)_{i=1}^l,K') \leq l M_1$.
Hence, as input to the stage above we may successively try the values $M_1
2^k$, $k \in \set{0,\dots,\log_2 l}$, stopping the first time we find a valid
coloring. 
\end{proof}

Lemma~\ref{lem:partial-via-volume} should be viewed as a volumetric analogue of
a theorem of Rothvoss~\cite{rothvoss-giann}, who both extended and made
algorithmic vector balancing results of Giannopoulos~\cite{giannop}. We state a
slight variant of~\cite[Lemma 9]{rothvoss-giann} below.

% \dnote{I
% would like to say something about how you probably can't get this type of result
% using the determinant lower bound. In particular, you lose a log there even for
% partial coloring in $\ell_\infty$. I think this is better save for the intro,
% where its easier to compare things.} 

\begin{theorem}[Partial Colorings via Gaussian Measure]\label{thm:roth-giann}
Let $0 < \eps \leq 1/60000$ and $\delta = \frac{3}{2}\eps \log_2
\frac{1}{\eps}$. Let $K \subseteq \R^n$ be a symmetric convex body given by a
membership oracle, and assume that for some subspace $H \subseteq \R^n$ of
dimension at least $(1-\delta)n$, we have that $\gamma_H(K) \geq e^{-\delta n}$.
Then for any $y \in (-1,1)^n$, there exists a polynomial time algorithm which
with high probability finds $x \in [-1,1]^n$ satisfying $|\bnds(y)| \geq \eps
n/2$ and $x-y \in K$.
\end{theorem}

We recall that Rothvoss' algorithm, for the special case $y = 0$ (the general
case is similar), works by computing the Euclidean projection of a Gaussian
random vector onto $K \cap [-1,1]^n$. The above statement deviates from the
corresponding Lemma in~\cite{rothvoss-giann} in that it does not assume that $K
\subseteq H$ or that $H$ is known to the algorithm. It is not hard to verify
however that this condition is not needed in analysis, so we defer discussion of
the proof of this statement to the full version. The flexibility gained by not
needing to know the subspace in advance will be very useful in the sequel. We
note that one can also adapt the analysis of the algorithm of Singh and
Eldan~\cite{ES14}, which maximizes over $K \cap [-1,1]^n$ using the Gaussian as
the objective vector instead of projecting it, to work in the above setting.   

Our proof of Lemma~\ref{lem:partial-via-volume} will in fact be a direct
reduction to Rothvoss' theorem. The core of our reduction is the following
geometric theorem, which shows that if all the coordinate sections of $K$ of
proportional dimension have large volume, then there exists a subspace $H$ of
proportional dimension on which $K$ has large Gaussian measure. 

\begin{theorem}[Gaussian Measure via Volume]
\label{thm:gauss-via-volume}
There exists a decreasing function $\eta: (0,1) \rightarrow \R_+$, $\eta(\delta)
= e^{O(1/\delta)}$, such that the following holds. For any $n \in \N$, $K
\subseteq \R^n$ symmetric convex body, $2 \leq k \leq n-1$, $\alpha = k/n$, such
that $\forall S \subseteq [n]$, $|S| = \alpha n$, $\vol_{\delta n}(K_S) \geq 1$,
there exists a linear subspace $H$ of dimension $(1-\delta)n$ for which
$\gamma_H(\eta(\delta) K) \geq e^{-\delta n}$.
\end{theorem}

We note that the above theorem is primarily interesting in the case where
$\delta$ is a fixed constant, as $\eta(\delta) = e^{O(1/\delta)}$ blows up quite
quickly as $\delta \rightarrow 0$. Lemma~\ref{lem:partial-via-volume} now
follows directly combining the above with Theorem~\ref{thm:roth-giann}, as shown
below.

\begin{proof}[Proof of Lemma~\ref{lem:partial-via-volume}] 
Let $\eps = 1/60000$ and $\delta = (3/2) \eps \log_2(1/\eps)$. By
Theorem~\ref{thm:gauss-via-volume}, $\eta(\delta) K$ satisfies the conditions
for applying Theorem~\ref{thm:roth-giann} on any $x \in (-1,1)^n$ with
`parameters $\eps$ and $\delta$ as in the last sentence. This yields
Lemma~\ref{lem:partial-via-volume} with $\eps_0 = \eps/2$, $\delta = \delta$ and
$C = O(\eta(\delta)) = O(1)$, as needed.   
\end{proof}

While there are examples where the volume lower bound is a $O(\log n)$ factor
off from hereditary discrepancy (e.g.~$3$ permutations), we conjecture that the
volume lower bound actually characterizes a hereditary version of partial
coloring discrepancy. Namely, if the volume lower bound is $D$, we conjecture
that there exists a subset of vectors for which every (fractional) partial coloring
has discrepancy $\Omega(D)$. Recall that Lemma~\ref{lem:partial-via-volume}
gives the other direction, i.e.~that there always exist partial colorings of
discrepancy $O(D)$. If this conjecture were true, then Rothvoss' algorithm,
which we use as a blackbox, would in a weak sense be optimal for finding
partial colorings. We discuss this conjecture in more detail in the next
subsection. 

Comparing to prior works, Theorem~\ref{thm:gauss-via-volume} provides a useful
and different route for proving that a body (or at least a large section of it)
has exponentially small Gaussian measure. In the context of discrepancy, to the
authors' knowledge, only two main techniques were used to prove such bounds,
neither of which is directly applicable in the above setting. The first
technique consists of combining chaining techniques and moment bounds, which can
generally only measure when the body has Gaussian measure close to $1/2$.  This
approach loses the leverage we have in only needing exponentially small bounds
and thus often incurs additional logarithmic factors. The second strategy is
based on the positive correlation properties of Gaussian measure, first proved
for the intersection of symmetric slabs (i.e.~Sidak's lemma), and with the
recent resolution of the Gaussian correlation conjecture~\cite{Royen14}, for the
intersection of arbitrary symmetric convex bodies. More precisely, one tries to
show that $K$ contains (or equals) the intersection of ``simpler'' symmetric
convex bodies $K_1,\dots,K_T$ (most often slabs) to deduce that $\gamma_n(K)
\geq \prod_{i=1}^T \gamma_n(K_i)$, from which one can usefully get exponentially
small bounds.

In contrast, our proof of the $e^{-\delta n}$ lower bounds on Gaussian measure
in the above theorem proceeds via a direct covering argument. Namely, if one can
show that $e^{\delta n-1}$ translates of $K$ cover the Euclidean ball of radius
$\sqrt{n}$, which has Gaussian measure $\geq 1/2$, then one can directly deduce
that 
\[
1 \leq 2\gamma_n(\sqrt{n}B_2^n) \leq 2N(\sqrt{n} B_2^n,K) \max_{t \in \R^n}
\gamma_n(K+t) \leq e^{\delta n} \gamma_n(K) ,
\]
where we have used that $\max_{t \in \R^n} \gamma_n(K+t) = \gamma_n(K)$ for a
centrally symmetric convex body, which follows by the symmetry and logconcavity
of Gaussian measure. We will adopt this strategy on a section of $K$, which is
chosen to align with the longest axes of a so-called regular M-ellipsoid for
$K$. The volumetric condition in Lemma~\ref{lem:partial-via-volume} will in fact
be used to guarantee that these axes have length $\Omega(\sqrt{n})$, which makes
the above strategy plausible. We recall that an M-ellipsoid~ $E$ of $K$ is an
ellipsoid which approximates $K$ well from the perspective of covering,
i.e.~$2^{O(n)}$ shifts of $K$ suffice to cover $E$ and vice versa. The existence
of such ellipsoids was first proven by Milman~\cite{Milman86-reverseBM}. We give
precise definitions below. 

For any two sets $A,B \subseteq \R^n$, let 
\[
N(A,B) = \min \set{|\Lambda|: \Lambda \subset \R^n, A \subseteq \Lambda+B} ,
\]
denote the minimum number of shifts of $B$ needed to cover $A$. The following
theorem of Pisier~\cite{Pisier-book}, gives the existence of M-ellipsoids whose
covering estimates have polynomial decay. The decay estimate will be used to
make the Gaussian measure of the large section of $K$ we find as close to $1$ as
we like after a sufficient scaling. 

\begin{theorem}[Regular M-ellipsoid]
\label{thm:reg-m}
There exists an absolute constant $c_0 > 0$, such that any $0 < \alpha < 2$,
letting $\sigma(\alpha) = c_0(2-\alpha)^{-1/2}$, $n \in \N$, and symmetric
convex body $K \subseteq \R^n$, there exists an ellipsoid $E \subseteq \R^n$,
$\vol_n(E)=\vol_n(K)$, such that for all $t \geq 1$
\[
\max \set{N(K,tE),N(E,tK),N(K^\circ,tE^\circ),N(E^\circ,tK^\circ)} \leq
e^{\sigma(\alpha) n / t^\alpha} \text{ .}
\]
Such an ellipsoid will be referred to as an $\alpha$-regular M-ellipsoid.
\end{theorem}


To show that the axes of the M-ellipsoid of $K$ are long, we will need to relate
the axis lengths to the volumes of coordinate projections of the polar
ellipsoid. For this, purpose we will require the following formula for
coordinate projection volumes. 

\begin{lemma}\label{lem:ellipsoid-volumes}
Let $E := E(Q) \subseteq \R^n$ be an origin center ellipsoid. Then, for any
$S \subseteq [n]$, $|S| = k$, we have that 
\[
\vol_k(\pi_S(E^\circ)) = \kappa_k \det(Q_{S,S})^{1/2} \text{ .}
\]
\end{lemma}
\begin{proof}
Recall that $E^\circ = E(Q^{-1}) = Q^{1/2} B_2^n$, where $Q^{1/2}$ is the
positive definite square root of $Q$. To begin, we recall that the support
function of $E^\circ$ can be computed by
\begin{align*}
h_{E^\circ}(w) &\eqdef \max_{y \in E^\circ} \inner{w}{y} 
               = \max_{z \in B_2^n} \inner{w}{Q^{1/2} z} 
               = \|Q^{1/2} w\| = \sqrt{w^\T Q w}.
\end{align*}
Let $W_S = \lspan\{e_i: i \in S\}$. Note that by construction, $\pi_S(E^\circ)
\subseteq W_S$ and $h_{\pi_S(E^\circ)}(w) = h_{E}(w)$, $\forall w \in W_S$.
Furthermore, by duality, among convex bodies these conditions uniquely define $\pi_S(E^\circ)$. 

Let $s_1 < s_2 < \dots < s_k$ be the elements of $S$ and let $P_S =
(e_{s_1},\dots,e_{s_k})$, noting that $P_S P_S^\T = \pi_S$. Let $T = P_S
(Q_{S,S})^{1/2} \in \R^{n \times k}$. We now show that $TB_2^k = \pi_S(E^\circ)$
using the aforementioned conditions. Clearly $TB_2^k \subseteq W_S$ since
$\lspan(P_S) = W_S$. For $w \in W_S$, letting $w_S = (w_{s_1},\dots,w_{s_k})^\T$
denote the restriction to the coordinates in $S$, we have that 
\begin{align*}
h_{TB_2^k}(w) &= \max_{z \in B_2^k} \inner{T^\T w}{z} 
              = \max_{z \in B_2^k} \inner{(Q_{S,S})^{1/2} w_S}{z} \\ 
              &= \sqrt{w_S^\T Q_{S,S} w_S} = \sqrt{w^\T Q w} ,
\end{align*} 
where the last equality follows since $w_i = 0$ for $i \notin S$. Thus
$\pi_S(E^\circ) = TB_2^k$ as claimed. The volume can now be computed as follows:
\begin{align*}
\vol_k(TB_2^k) &= \kappa_k \det(T^\T T)^{1/2} 
               = \kappa_k \det((Q_{S,S})^{1/2} (P_S^\T P_S)
(Q_{S,S})^{1/2})^{1/2} \\
               &= \kappa_k \det(Q_{S,S})^{1/2} \text{ ,}
\end{align*}
as needed.
\end{proof}


We now have all the ingredients needed to prove our main geometric estimate.

\begin{proof}[Proof of Theorem~\ref{thm:gauss-via-volume}]
Let $E := E(Q)$ denote a $1$-regular M-ellipsoid for $K$ and let $\sigma :=
\sigma(1)$. Let $l_1 \geq \dots \geq l_n > 0$ denote
the length of the principal axes of $E$, where we recall that
$l_n^{-2}\geq \dots \geq l_1^{-2} > 0$ are then the eigenvalues of $Q$.

By the Blaschke-Santal{\'o} inequality, for all $S \subseteq
[n]$, $|S|=\delta n$, we have that 
\[
\vol_{\delta n}(K_S)\vol_{\delta n}((K_S)^\circ) = 
\vol_{\delta n}(K_S) \vol_{\delta n}(\pi_S(K^\circ)) \leq
\kappa_{\delta n}^2 \text{ .}
\]
Since we assume $\vol_{\delta n}(K_S) \geq 1$, the above implies that
$\vol_{\delta n}(\pi_S(K^\circ)) \leq \kappa_{\delta n}^2$. The
coordinate projections of $E^\circ$ thus have volume at most 
\[
\vol_{\delta n}(\pi_S(E^\circ)) \leq N(E^\circ,K^\circ)
\vol_{ \delta n}(\pi_S(K^\circ)) \leq e^{\sigma n} \kappa_{\delta n}^2 \text{ .}
\]
Combining Lemma~\ref{lm:rip-det} and~\ref{lem:ellipsoid-volumes}, we have that
\begin{align*}
\prod_{i=(1-\delta)n+1}^n l_i^{-1} &\leq \binom{n}{\delta n}^{1/2} \max_{S \subseteq
[n],|S|=\delta n} \det(Q_{S,S})^{1/2} \\
&= \binom{n}{\delta n}^{1/2} \max_{S \subseteq [n],|S|=\delta n}
\vol_{\delta n}(\pi_S(E^\circ)) \kappa_{\delta n}^{-1} \\
&\leq \binom{n}{\delta n}^{1/2} e^{\sigma n} \kappa_{\delta n} \text{ .}
\end{align*}
From here, we conclude that 
\begin{equation}
\label{eq:axis-long}
l_{(1-\delta)n} \geq \prod_{i=(1-\delta)n+1}^n l_i^{\frac{1}{\delta
n}} \geq \binom{n}{\delta 
n}^{-\frac{1}{2\delta n}} e^{-\frac{\sigma}{\delta }} \kappa_{\delta
n}^{-\frac{1}{\delta n}} \geq 
\frac{1}{e^{2\frac{\sigma}{\delta }}} \cdot \sqrt{\frac{\delta n}{2\pi e}} :=
c(\delta)^{-1} \sqrt{n} \text{ .}
\end{equation}
Letting $H$ be the span of the first $(1-\delta)n$ principal
axes of $E$, we thus conclude that 
\[
\sqrt{n} (B_2^n \cap H) \subseteq c(\delta) (E \cap H). 
\]
Using the $1$-regularity of $E$, letting $t = 2 \sigma / \delta$, we derive the
following covering estimate 
\begin{align*}
N(\sqrt{n} (B_2^n \cap H), 2 t c(\delta) (K \cap H))
&\leq N(c(\delta)(E \cap H), 2 t c(\delta) (K \cap H)) \\
&\leq N(E, t K) \leq e^{\sigma n / t} = e^{\delta n/2} \text{ .}
\end{align*}
Since $\gamma_H(\sqrt{n} B_2^n \cap H) \geq 1/2$, setting $\eta := \eta(\delta)
=\frac{2c(\delta)\sigma}{\delta} = e^{O(1/\delta)}$, we get that $\gamma_H(\eta K
\cap H) \geq \frac{1}{2} e^{-\delta n/2} \geq e^{-\delta n}$, as needed. Lastly,
$\eta$ as defined above is easily checked to be decreasing in $\delta$.
\end{proof}

\subsection{The Discrepancy of Partial Colorings}
\label{sec:rip-convex}

In this section we discuss a geometric conjecture which would imply that a tight
relationship between the discrepancy of partial colorings and the volume lower
bound, and thus a weak form of optimality for Rothvoss' partial coloring
algorithm. For this purpose, we formally define the partial coloring discrepancy
as well as its hereditary version. Given $(u_i)_{i=1}^N \in \R^n$, symmetric
convex body $K \subseteq \R^n$ and $\alpha \in (0,1]$,  we define  
\begin{equation}
\label{def:partial-disc}
\begin{split}
&\disc_\alpha(( u_i)_{i=1}^N,K) \eqdef \min_{\substack{x \in [-1,1]^N \\
|\bnds(x)| \geq \alpha N}} \Bigl\|\sum_{i=1}^N x_i u_i\Bigr\|_K .
\end{split}
\end{equation}
and
\begin{equation}
\label{def:partial-hd}
\hd_\alpha((u_i)_{i=1}^N,K) \eqdef \max_{S \subseteq [N]} \disc_\alpha((u_i)_{i \in S}, K) .
\end{equation}

We recall that (repeated applications) of Lemma~\ref{lem:partial-via-volume}
implies the upper bound
\[
\hd_{1/2}((u_i)_{i=1}^N,K) \leq O(1) \vollb^{\rm h}((u_i)_{i=1}^N,K).
\]
Here we conjecture that the reverse inequality should also hold.

\begin{conjecture}
\label{conj:partial-volume}
There exists a universal constant $c \geq 1$, such that for any $n \in \N$,
$u_1,\dots,u_n \in \R^n$ linearly independent and symmetric convex body $K
\subseteq \R^n$: 
\begin{equation}
\vollb^{\rm h}((u_i)_{i=1}^n,K) \leq c \hd_{1/2}((u_i)_{i=1}^n,K)
\end{equation}
\end{conjecture}

Note that we restrict above to linear independent subsets of vectors, but as is
well-known (e.g.~see proof of Theorem~\ref{thm:tightness}), this is without loss
of generality. As a pathway to prove the conjecture, we suggest the following
natural geometric analog of the so-called spectral lower bound for discrepancy
into $\ell_2$.

\begin{lemma}
\label{lem:speclb}
Let $U=(u_1,\dots,u_n) \in \R^{n \times n}$ be linearly independent, $K
\subseteq \R^n$ be a symmetric convex body, and $\alpha \in [0,1]$. For any
subset $S \subseteq [n]$, $|S|=k$, letting $W_S := \lspan\{u_i: i \in S\}$,
define
\[
\speclb((u_i)_{i \in S},K) := 
\max \set{r \geq 0: r K \cap W_S \subseteq \sqrt{|S|} U_S B_2^k }.
\]
Then, we have that
\begin{equation}
\label{eq:spec-lb}
\disc_\alpha((u_i)_{i \in S},K) \geq \sqrt{\alpha} \speclb((u_i)_{i \in S},K).
\end{equation}
In particular, defining
\[
\speclb^{\rm h}((u_i)_{i=1}^n,K) := \max_{S \subseteq [n]} \speclb((u_i)_{i \in
S},K)
\]
we have that
\begin{equation}
\label{eq:hd-spec-lb}
\hd_{\alpha}((u_i)_{i=1}^n,K) \geq \sqrt{\alpha} \speclb^{\rm h}((u_i)_{i=1}^n,K).
\end{equation}
\end{lemma}
\begin{proof}
We prove only~\eqref{eq:spec-lb} since then \eqref{eq:hd-spec-lb} follows
trivially. For~\eqref{eq:spec-lb}, by replacing $K$ by $K \cap W_S$, we may wlog
assume that $|S|=n$ and $W_S = \R^n$. 

Let $x \in [-1,1]^n$, $|\bnds(x)| \geq \alpha n$, and $u_x = \sum_{i=1}^n x_i
u_i$. Our goal is to show that $\beta := \norm{u_x}_K \geq \sqrt{\alpha} r$, where $r
:= \speclb((u_i)_{i=1}^n,K)$.

Let $(u_i^*)_{i=1}^n$ denote the corresponding dual basis of
$(u_i)_{i=1}^n$, i.e.~satisfying $\inner{u_i^*}{u_j} = 1$ if $i=j$ and $0$
otherwise, which exists by linear independence. Now letting $v_x =
\sum_{i=1}^n \frac{x_i}{\norm{x}_2} u_i^*$, it is easy to check that 
\[
\inner{v_x}{u_x} = \norm{x}_2 \geq \sqrt{|\bnds(x)|} \geq \sqrt{\alpha n}.
\]
Since $u_x \in \beta K$ and $r K \subseteq \sqrt{n} U B_2^n$, we have that
\begin{align*}
\sqrt{\alpha n} \leq \beta \max_{z \in K} \inner{v_x}{z} 
         \leq \frac{\beta}{r} \sqrt{n} 
               \max_{z \in UB_2^n} \inner{v_x}{z}
          = \frac{\beta}{r} \sqrt{n} \max_{z \in B_2^n}
\inner{\frac{x}{\norm{x}_2}}{z}
 = \frac{\beta}{r} \sqrt{n} .
\end{align*}
The desired inequality now follows by rearranging.
\end{proof}

We note that as with $\vollb^{\rm h}$, one may extend the $\speclb^{\rm h}$ to
an arbitrary sequence of vectors $(u_i)_{i=1}^N$, however one must take care to
optimize only over subsets of linearly independent vectors, since otherwise the
conclusion of Lemma~\ref{lem:speclb} is false.

Given the above, it suffices to prove Conjecture~\ref{conj:partial-volume} with
$\hd_{1/2}$ replaced by $\speclb^{\rm h}$. The resulting stronger conjecture has a
very natural geometric interpretation which we expand on below. For
$(u_i)_{i=1}^n \in \R^n$ linearly independent and $K \subseteq \R^n$ a symmetric
convex body, letting $T$ denote the linear map sending $(u_i)_{i=1}^n$ to
$(e_i)_{i=1}^n$, it is direct to check that $\tau((u_i)_{i=1}^n,K) =
\tau((e_i)_{i=1}^n,TK)$ for $\tau \in \set{\speclb^{\rm h},\vollb^{\rm h}}$.
Thus, for the purpose of the conjecture, it suffices to consider the setting
where the vectors are the standard basis. In this setting, we see that
\[
\speclb^{\rm h}((e_i)_{i=1}^n,K) = \max_{S \subseteq [n]} \max \set{r \geq
0: r K_S \subseteq \sqrt{|S|} B_2^S} 
\]
and that 
\[
\vollb^{\rm h}((e_i)_{i=1}^n,K) = \max_{S \subseteq [n]}
\vol_{|S|}(K_S)^{-1/|S|} \text{ .} 
\]
The goal is now to show that for every $S_0 \subseteq [n]$, there exists $S_1
\subseteq [n]$, such that 
\begin{equation}
\label{eq:conj-simple}
\vol_{|S_0|}(K_{S_0})^{-1/|S_0|} \leq c \max \set{r \geq 0: r K_{S_1} \subseteq
\sqrt{|S_1|} B_2^{|S_1|}} \text{ .}
\end{equation}
Since this must hold for every symmetric convex body $K$, we may assume that
$S_0 = [n]$ (and thus $S_1 \subseteq S_0$). Furthermore, by homogeneity, we may
also assume that $\vol_n(K)=1$. In this case~\eqref{eq:conj-simple}, and hence
Conjecture~\ref{conj:partial-volume}, directly reduces to the following
geometric conjecture.

\ripconvex*
% \begin{conjecture}[Restricted Invertibility Principle for Convex Bodies]
% \label{conj:conv-restr-iso} There exists an absolute constant $c \geq 1$, such
% for any $n \in \N$, symmetric convex body $K \subseteq \R^n$ of volume $1$,
% there exists $S \subseteq [n]$ such that $K_S \subseteq c |S| B_1^S$.
% \end{conjecture}

Two natural weakenings of Conjecture~\ref{conj:rip-convex} are to ask whether
(a) it holds for ellipsoids and (b) whether it holds for general bodies but with
coordinate sections replaced by arbitrary sections. As our main evidence for the
conjecture, we show that both statements are true. We note that (a) indeed
implies Conjecture~\ref{conj:partial-volume} when $K$ is an ellipsoid. We state
our results formally below.

\begin{theorem}
\label{thm:partial-conjecture}
There exists a universal constant $c \geq 1$, such that any $n \in \N$, the
following holds:
\begin{enumerate}
\item For any origin centered ellipsoid $E \subseteq \R^n$ of volume at most
$1$, there exists $S \subseteq [n]$, $S \neq \emptyset$, such that $E_S
\subseteq c \sqrt{|S|} B_2^S$.
\item For any symmetric convex body $K \subseteq \R^n$ of volume at most $1$,
there exists a linear subspace $W \subseteq \R^n$, such that $K \cap W \subseteq
c \sqrt{W} B_2^W$.
\end{enumerate}
\end{theorem}

To prove the above theorem, we will need the following two lemmas.  
\begin{lemma}
\label{lem:axis-m-ell}
Let $K \subseteq \R^n$ be a symmetric convex body of volume $1$ satisfying for
all $S \subseteq [n]$, $\vol_{|S|}(K_S) \geq 1$. Let $E \subseteq \R^n$ be a
$1$-regular M-ellipsoid of $K$. Then there exists $S \subseteq [n]$, $|S| \geq
a_1 n$, such that $E_S \subseteq a_2 \sqrt{|S|} B_2^S$, where $a_1,a_2 > 0$ are
universal constants.
\end{lemma}
\begin{proof}
Let $E = E(Q)$ be a $1$-regular M-ellipsoid of $K$. Recall that $N(K,E) \leq
N(E,K) \leq e^{\sigma n}$ where $\sigma := \sigma(1)$ and that
$\vol_n(K)=\vol_n(E)=1$. Let $\lambda_1 \geq \cdots \geq \lambda_n > 0$ denote
the axes of the M-ellipsoid, where $1/\lambda_n^2 \geq \cdots \geq 1/\lambda^2_1
> 0$ are the eigenvalue of $Q$.

Recall by the proof of Theorem~\ref{thm:gauss-via-volume}
(equation~\eqref{eq:axis-long}), we have for that 
\begin{equation}
\label{eq:axes-long}
\lambda_{\ceil{(3/4)n}} \geq e^{-O(4/3)}\sqrt{n} \geq c_1 \sqrt{n}, 
\end{equation}
where $c_1 > 0$ is an absolute constant. 

We now show that assuming $\vol_n(E)=1$, that the central axes also have length
$O(\sqrt{n})$. Let $k = \floor{\frac{1}{4} n}$. By Lemma~\ref{lm:rip-det}
applied to $Q^{-1}$, there exists $S \subseteq [n]$, such that
\begin{equation}
\label{eq:short-axes}
\prod_{i=1}^k \lambda_i^2 \leq \binom{n}{k} \det((Q^{-1})_{S,S}). 
\end{equation}

Let $R = [n] \setminus S$. Using the fact that $(Q^{-1}_{S,S})^{-1}$ is the
Schur complement of $Q$ with respect to $Q_{R,R}$ block, we have the identity 
\begin{equation}
\det(Q) = \det(Q_{R,R}) \det((Q^{-1}_{S,S})^{-1}) \Leftrightarrow
\frac{\det(Q)^{-1}}{\det((Q_{R,R}))^{-1}} = \det((Q^{-1})_{S,S}) .
\end{equation}
From here, since $\vol_n(E)=1$, we have that
\begin{equation}
\label{eq:identity}
\begin{split}
\frac{\det(Q)^{-1}}{\det((Q_{R,R}))^{-1}} &= \frac{\kappa^2_{n-k}
\vol_n(E)^2}{\kappa^2_n \vol_{n-k}(E_R)^2} = \frac{\kappa^2_{n-k}}{\kappa_n^2}
\frac{1}{\vol_{n-k}(E_R)^2} \\
&\leq \frac{\kappa^2_{n-k}}{\kappa_n^2} \frac{e^{2\sigma n}}{\vol_{n-k}(2K_R)^2}
\leq \frac{\kappa^2_{n-k}}{\kappa_n^2} e^{4\sigma n}.
\end{split}
\end{equation}
Combining~\eqref{eq:short-axes} and~\eqref{eq:identity}, using that $k =
\floor{n/4}$, we get that
\begin{equation}
\label{eq:axes-short}
\lambda_k \leq (\prod_{i=1}^k \lambda_i)^{1/k} \leq \binom{n}{k}^{1/(2k)}
(\frac{\kappa_{n-k}}{\kappa_n})^{1/k} e^{2\sigma n/k} \leq c_2 \sqrt{n},
\end{equation}
where $c_2 \geq 1$ is an absolute constant. Given the above, we have that
\begin{equation}
\label{eq:axis-sandwich}
c_1 \sqrt{n} \leq \lambda_{\ceil{(3/4)n}} \leq \lambda_{\floor{(1/4)n}} \leq c_2
\sqrt{n} \text{ .}
\end{equation}
Let $W$ denote the span of axes of $E$ associated with
$\lambda_{\floor{(1/4)n}},\dots,\lambda_{\ceil{(3/4)n}}$ and let $\pi_W$ denote
the corresponding orthogonal projection. Let $Q' = Q^{1/2}\pi_WQ^{1/2} \preceq
Q$, noting that $Q'$ preserves all the eigenvalues associated with $W$ while
setting the others to zero. Applying Theorem~\ref{thm:rest-inv} to $Q'$ with
$\eps=1/2$, we get a subset $S \subseteq [n]$, which by~\eqref{eq:axis-sandwich}
and our choice of $W$ has size at least
\[
|S| = \frac{1}{4} \frac{\tr(Q')}{\lambda_{\rm max}(Q')} \geq c_3 n
\]  
where $c_3 > 0$ is an absolute constant. Furthermore,
\[
\lambda_{\rm \min}(Q_{S,S}) \geq \lambda_{\rm min}(Q'_{S,S}) \geq
\frac{\tr(Q')}{n} \geq \frac{1}{2} \lambda_{\floor{(1/4)n}}^{-2} \geq c_4/n \text{ ,}
\]
where $c_4 > 0$ is an absolute constant. Noting that the above implies that
$E_S \subseteq \sqrt{n/c_4} B_2^S$ completes the proof, setting $a_1 = c_3$ and
$a_2 = 1/\sqrt{c_4}$.
\end{proof}

The next lemma is essentially a consequence of Milman's quotient of subspace
theorem, whose proof we defer to the full version.

\begin{lemma}
\label{lem:cover-to-section}
Let $K \subseteq \R^n$ be a symmetric convex body such that $N(K,\sqrt{n}B_2^n)
\leq 2^{O(n)}$. Then there exists a linear subspace $W \subseteq \R^n$, $\dim(W) =
\Theta(n)$, such that $K \cap W \subseteq O(\sqrt{|W|}) B_2^W$.  
\end{lemma}

Given the above two lemmas, we can now prove our main theorem.

\begin{proof}[Proof of Theorem~\ref{thm:partial-conjecture}]
Firstly, for both statements, we note that we may in fact that additionally
assume that $\vol_{|S|}(K_S) \geq 1$ for all $S \subset [n]$. This follows by
noting that if there exists $S \subset [n]$ with $\vol_{|S|}(K_S) < 1$, we may
simply apply induction on $K_S$, after scaling it up to have volume $1$ (which
only makes the task more difficult). 

\paragraph{\bf Proof of 1.} When $K$ is an ellipsoid, the statement follows
immediately by applying Lemma~\ref{lem:axis-m-ell} with $E=K$. 

\paragraph{\bf Proof of 2.} First apply Lemma~\ref{lem:axis-m-ell} to $K$,
noting that the produced section $K_S$ now satisfies the conditions of
Lemma~\ref{lem:cover-to-section}, from which we derive the result.  
\end{proof}
